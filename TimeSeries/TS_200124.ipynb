{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1749ea4a-2ad4-4dd6-a2df-f4627f8253b7",
   "metadata": {},
   "source": [
    "## **CHARACTERISTICS OF A SERIES**\n",
    "- for a time series $\\{Y_t\\:,t=0,\\pm 1,\\pm 2,\\dots\\}$\n",
    "* THE MEAN FUNCTION<br><p style=text-align:center;>$\\mu_t=E[Y_t]$</p>\n",
    "    * $E[Y_t]$ is the expected value of the process at time $t$\n",
    "    * This exists iff $E|Y_t|\\leq\\infty$\n",
    "- THE VARIANCE FUNCTION<br><p style=text-align:center;>$\\sigma_t^2=\\gamma_0=\\text{Var}(Y_t)=E(Y_t-\\mu_t)^2=E(Y_t^2)-\\mu_t^2<\\infty$</p>\n",
    "    * $\\gamma_0\\geq 0$\n",
    "    \n",
    "* THE AUTOCOVARIANCE FUNCTION<br><p style=text-align:center;>$\\gamma_{t,s} = \\text{Cov}(Y_t,Y_s)=E[(Y_t-\\mu_t)(Y_s-\\mu_s)]$</p>\n",
    "    * $=E(Y_tY_s)-\\mu_t\\mu_s\\:,t,s=0,\\pm1,\\pm2,\\dots$\n",
    "    * This is the covariance between the value at time $t$ and the value at time $s$ of a stochastic process $Y_t$\n",
    " \n",
    "- THE AUTOCORRELATION FUNCTION<br><p style=text-align:center;>$\\rho_{t,s} = \\text{Corr}(Y_t,Y_s)=\\gamma_{t,s}/\\sigma_t\\sigma_s\\:, -1\\leq\\rho_{t,s}\\leq 1$</p>\n",
    "    * This is the correlation of the series with itself\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80175d3b-4138-4b3c-a505-e6ed0dcec5d4",
   "metadata": {},
   "source": [
    "### **STRONG STATIONARY PROCESS**\n",
    "\n",
    "* $f_{Y_{t_1}\\dots Y_{t_n}}(y_1,\\dots,y_n) = f_{Y_{t_1+k}\\dots Y_{t_n+k}}(y_1,\\dots,y_n)$\n",
    "\n",
    "\n",
    "- $E[Y_t] = E[Y_{t+k}]\\rightarrow \\mu_t = \\mu_{t+k} = \\mu\\:,\\forall t,k$\n",
    "    * The expected value of a series is constant over time, not a function of time\n",
    "\n",
    "\n",
    "* $\\text{Var}[Y_t] = \\text{Var}[Y_{t+k}]\\rightarrow \\sigma_t^2 = \\sigma_{t+k}= \\sigma\\:,\\forall t,k$\n",
    "    * The variance of a series is constant over time, *homoscedastic*\n",
    "    \n",
    "    \n",
    "- $\\text{Cov}[Y_t,Y_s] = \\text{Cov}[Y_{t+k},Y_{s+k}]\\rightarrow \\gamma_{t,s} = \\gamma_{t+k,s+k}\\:,\\forall t,k$\n",
    "    * $\\rightarrow \\gamma_{|t-s|}=\\gamma_{|t+k-s-k|}=\\gamma_h$\n",
    "    * Not constant, not dependent on time, depends on *time interval*, which we call **lag**, $k$\n",
    "    \n",
    "    \n",
    "* $\\text{Corr}[Y_t,Y_s] = \\text{Corr}[Y_{t+k},Y_{s+k}]\\rightarrow \\rho_{t,s} = \\rho_{t+k,s+k}\\:,\\forall t,k$\n",
    "    * $\\rightarrow \\rho_{|t-s|}=\\rho_{|t+k-s-k|}=\\rho_h$\n",
    "    * Let $t=t-k$ and $s=t$<p style=text-align:center;>$\\rho_{t,t-k}=\\rho_{t+k,t}=\\rho_k\\:,\\forall t,k$</p>\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa576523-159d-42d3-acd0-279288699051",
   "metadata": {},
   "source": [
    "## **WEAK STATIONARITY** or **STATIONARY IN A WIDE SENSE** (WSS)\n",
    "* A time series is said to be **covariance stationary** if its first and second order moments are unaffected by a change of time origin\n",
    "* That is, we have constant mean and variance with covariance and correlation being functions of time difference only\n",
    "\n",
    "---\n",
    "* So for a WEAK STATIONARY PROCESS\n",
    "\n",
    "- $E[Y_t]=\\mu\\:,\\forall t$\n",
    "\n",
    "* $\\text{Var}[Y_t] = \\sigma^2\\leq\\infty\\:,\\forall t$\n",
    "\n",
    "- $\\text{Cov}[Y_t,Y_{t-k}]=\\gamma_k\\:,\\forall t$\n",
    "\n",
    "* $\\text{Corr}[Y_t,Y_{t-k}]=\\rho_k\\:,\\forall t$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b35df59-8afa-41df-8e62-e813e85ff5bd",
   "metadata": {},
   "source": [
    "## AutoCovariance Function (ACF)\n",
    "- THE AUTOCOVARIANCE FUNCTION<br><p style=text-align:center;>$\\gamma_{t,s} = \\text{Cov}(Y_t,Y_s)=E[(Y_t-\\mu_t)(Y_s-\\mu_s)]$</p>\n",
    "  *  $=E(Y_tY_s)-\\mu_t\\mu_s\\:,t,s=0,\\pm1,\\pm2,\\dots$\n",
    "    * This is the covariance between the value at time $t$ and the value at time $s$ of a stochastic process $Y_t$\n",
    "- For a stationary time series, the mean is constant and the dependence is only a function of the lag $k=t-s$\n",
    "- The ACF of a stationary process and its estimate are given by:\n",
    "  *  $\\gamma_{Y_t,Y_{t+k}}=\\gamma_k = E[(Y_t-\\mu)(Y_{t+k}-\\mu)]$\n",
    "  *  $\\hat{\\gamma}_k = r_k = \\frac{1}{N}\\Sigma_{t=1}^{N-k}(Y_t-\\mu)(Y_{t+k}-\\mu)$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce77a623-640e-420f-b80f-d08a54a87a99",
   "metadata": {},
   "source": [
    "* Given $\\hat{\\gamma}_k = \\frac{1}{N}\\Sigma_{t=1}^{N-k}(Y_t-\\mu)(Y_{t+k}-\\mu)$\n",
    "\n",
    "* suppose $\\mu=0$,\n",
    "  - $\\hat{\\gamma}_0=\\frac{1}{N}\\{y_1y_1+y_2y_2+\\dots+y_Ny_N\\}$\n",
    "  - $\\hat{\\gamma}_1=\\frac{1}{N}\\{y_1y_2+y_2y_3+\\dots+y_{N-1}y_{N}\\}$\n",
    "  - $\\hat{\\gamma}_2=\\frac{1}{N}\\{y_1y_3+y_2y_4+\\dots+y_{N-2}y_{N}\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c7e29f-4089-45ac-b701-e7c5700f4724",
   "metadata": {},
   "source": [
    "<img src='acfsine.png'>\n",
    "<img src='acfint.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadcd94a-22d0-41b9-b2b7-c6a754cd2a0d",
   "metadata": {},
   "source": [
    "## Properties of the ACF\n",
    "* ACF of a time-series is symmetric about the lag $k$\n",
    "* It takes the largest value at lag $k=0$\n",
    "* In practice, a normalized function known as the auto-correlation function is used:\n",
    "<p style=text-align:center;>$\\rho_k = \\text{Corr}(Y_t,Y_{t+k})=\\gamma_{t,t+k}/\\sigma_t\\sigma_{t+k}=\\gamma_k/\\sigma^2\\:, -1\\leq\\rho_k\\leq 1$</p>\n",
    "* This is the correlation of the series with itself"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e463f423-655a-4d1b-888a-8a3ff21a2d1c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cross-Covariance function (CCF)\n",
    "* The CCF is a measure of dependence between sample of a time-series $\\{x_t\\}$ and another time-series $\\{y_t\\}$\n",
    "* For stationary series, this is only a function of the distance between samples, that is the lag $k$\n",
    "* The CCF of a stationary process and its estimate are given by:\n",
    "    - $\\gamma_{XY}(k) = E[(x_t-\\mu_x)(y_{t+k}-\\mu_y)]$\n",
    "    - $\\hat{\\gamma}_{XY}(k)=r_{XY}(k) = \\frac{1}{N}\\Sigma_{t=1}^{N-k}(x_t-\\bar{x})(y_{t+k}-\\bar{y})$\n",
    " \n",
    "## Properties of the CCF\n",
    "* CCF of two time-series satisfies $\\gamma_{XY}(k)=\\gamma_{XY}(-k)$\n",
    "* The largest value occurs at lag where the dependency is strongest\n",
    "* In practice, a we used the normalized function, known as the cross-correlation function\n",
    "  - $\\rho_{XY}(k)=\\gamma_{XY}(k)/\\sigma_{XX}(0)\\sigma_{YY}(0)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a2b273-b49f-4f43-a5db-c99494c3aa6a",
   "metadata": {},
   "source": [
    "## Uses of ACF and CCF\n",
    "ACF and CCF are also defined for deterministic sequences in similar fashion.\n",
    "They have wide uses in system identification\n",
    "\n",
    "* The ACF is used in detecting the underlying process, i.e, whether it is periodic, moving average, auto-regressive, independent, etc\n",
    "* ACF is used in the estimation of the periodicity of an oscillatory process and the order of certain stochastic models\n",
    "* The CCF assumes the largest value when two time-series have the strongest correlation. This has wide applications in determining the time-delay of a system (an important step in the identification)\n",
    "* The cross-correlation function is the output of an LTI (linear-time-invariant) system whose input is the auto-correlation function. This relationship is used in the estimation of impulse response coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff6195c-c4ab-4fd8-81b0-e9ab978ea9d6",
   "metadata": {},
   "source": [
    "## Additional topics\n",
    "#### Quasi-Stationarity\n",
    "* Signal (sequence) whose mean is bounded and whose auto-covariance estimate becomes purely a function of lag as the number of samples become large, as said to be quasi-stationary.\n",
    "* Mathematically, a quasi-stationary signal has the properties\n",
    "  - $E[s(t)] = \\mu_s(t)\\hspace{20pt}|\\mu_s(t)|\\leq C,\\hspace{10pt}\\forall t$\n",
    "  - $E[s(r)s(t)] = r_s(t,r)\\hspace{20pt}|r_{ss}(t,r)|\\leq C$\n",
    "  - $\\lim_{N\\rightarrow\\infty}\\frac{1}{N}\\Sigma_{t=1}^Nr_s(t,t-l) =r_{ss}(l)\\hspace{10pt}\\forall l$\n",
    "#### Ergodicity\n",
    "* A stochastic process is said to be ergodic if the properties computed from a single realization coincide with that of the process, with a probability of 1, defined by taking the average of the ensemble of realizations\n",
    "* Rgodicity provides a framework that simplifies many calculations.\n",
    "* It also allows us to measure a physical quantity with a  single sensor and make reliable inferences\n",
    "* To a large extent, the problem of ergodicity deals with repetition of experiments\n",
    "* We will assume ergodicity throughout the course"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0232c389-4f97-4dbb-8224-0e054f1f2bf5",
   "metadata": {},
   "source": [
    "# Some Popular Stochastic Processes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc7227a-3871-4a13-817d-618149655101",
   "metadata": {},
   "source": [
    "## White Noise Processes \n",
    "* A process $\\{X_t\\}$ is called a white noise process if it is a sequence of uncorrelated random variables from a fixed distribution with constant mean $\\mu$, usually assumed to be zero, and constant variance $\\sigma^2$\n",
    "* The discrete-time white-noise sequence $\\{e_t\\}$ is a set of independent, identically distributed (iid) values belonging to a stationary stochastic process.\n",
    "* White-noise sequence exhibits an impulse-like ACF or constant power spectrum\n",
    "* It is a purely random process\n",
    "* Additional properties:\n",
    "  - $\\gamma_k = \\text{Cov}(Y_t,Y_{t+k})=0,\\hspace{10pt}k\\gt 0$\n",
    "  - $\\gamma_k\\left\\{\\begin{array}{ll} 1 & \\text{if}\\: k = 0 \\\\ 0 & \\text{if}\\: k \\neq 0 \\end{array}\\right.$\n",
    "* The power spectrum of white-noise is constant and given by:\n",
    "  - $\\Gamma_{ee}(\\omega)=\\frac{\\sigma_e^2}{2\\pi},\\hspace{10pt}\\forall \\omega$\n",
    "\n",
    "  ---\n",
    "## Random Walk or Browninan motion- A Non-Stationary process\n",
    "* RANDOM WALK: Let $e_1,e_2,\\dots$ be a sequence of iid r.vs with mean 0 and variance $\\sigma_e^2$, ($Y_t\\sim\\mathcal{N}(0,\\sigma^2)$ The observed time series is <br><p style=text-align:center;>$\\{Y_t,\\:t=1,2,\\dots,n\\}$</p>\n",
    "* It is obtained as:\n",
    "  - $Y_1=e_1$\n",
    "  - $Y_2 = e_1+e_2\\rightarrow Y_2=Y_1+e_2$\n",
    "  - $Y_3 = e_1+e_2+e_3\\rightarrow Y_3=Y_2+e_3$\n",
    "  - $\\dots$\n",
    "  - $Y_t = e_1+e_2+\\dots+e_t\\rightarrow Y_t=Y_{t-1}+e_t$\n",
    "  - $Y_t=\\Sigma^te_t$\n",
    "* So brownian motion is a summation of white noise\n",
    "* $\\sigma_Y^2=\\text{Var}(\\Sigma^te_t)=\\Sigma^t\\text{Var}(e_t)=\\Sigma^t\\sigma^2=t\\sigma^2$\n",
    "* Since the variance of the TS is time dependent, the time series is non-stationary\n",
    "* However, the first differences are stationary: $\\Delta y_t=y_t-y_{t-1}=e_t$\n",
    "---\n",
    "<img src='nonstat.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5166b496-3d7b-4d0b-a66f-325f757c93f7",
   "metadata": {},
   "source": [
    "## Moving Average (MA) Processes\n",
    "* $Y_t = \\Sigma_{k=1}^P\\theta_ke_{t-k}$, with $\\theta_0=1$, and $P$ is the **Model Order**, which tells us how many coefficients are in the model\n",
    "* What are the unknowns in the MA model? They are $P$ and $\\bar{\\theta}$, the coefficient (here represented with a vector)\n",
    "* For a given $P$, the variance $\\text{Var}(Y_t)=P\\sigma_e^2$- if $P$ is fixed, then variance is fixed. Therefore this is a stationary process for fixed $P$\n",
    "* Say we have $P=2$, then,\n",
    "  - $Y_t=\\theta_0e_t+\\theta_1e_{t-1}+\\theta_2e_{t-2}=e_t+\\theta_1e_{t-1}+\\theta_2e_{t-2}$\n",
    "  - where $e_t\\sim\\mathcal{N}(0,\\sigma^2)$ and all $e$ are iid. $\\theta_0=1$\n",
    "* Say the mean of the process will still be $\\mu_{Y_t}=0$, and the variance can be calculated as: $\\text{Var}(Y_t) = \\text{Var}(e_t+\\theta_1e_{t-1}+\\theta_2e_{t-2})=\\text{Var}(e_t)+\\theta_1^2\\text{Var}(e_{t-1})+\\theta_2^2\\text{Var}(e_{t-2})$\n",
    "  - Therefore, we get the variance as: $\\sigma_e^2+\\theta_1^2\\sigma_e^2+\\theta_2^2\\sigma_e^2$\n",
    "---\n",
    "Therefore, this is a stationary process, as the mean and variance are constant\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
