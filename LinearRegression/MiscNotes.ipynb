{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e6cecda-3f05-44a8-a6b6-bec735368363",
   "metadata": {},
   "source": [
    "# Multicollinearity in Regression\n",
    "### Why is it potentially a problem?\n",
    "* If the degree of correlation between variables is high enough, it can cause problems when you fit the model and interpret the results.\n",
    "*  A **key goal of regression analysis** is to isolate the relationship between each IV (independent variable) and DV (dependent variable)\n",
    "*  So the **interpretation of a regression coefficient** is- it is the mean change in the DV for each one-unit change in the IV, when you hold all the other independent variables constant\n",
    "\n",
    "---\n",
    "- The last portion is crucial for our discussion about multicollinearity.\n",
    "- In regression analysis, the idea is that we can change the  value of one IV and not the others.\n",
    "- However when they are correlated, it indicates that changes in one IV are associated with shifts in another.\n",
    "- The stronger the correlation, the harder it is to change one IV without changing another.\n",
    "- It becomes difficult for the model to esitmate the relationship between each IV and the DV independently because the IV tend to change in unision\n",
    "\n",
    "---\n",
    "### Types of Multicollinearity\n",
    "* There are two types of Multicollinearity:\n",
    "  1. Structural: By product of model and not the data *eg* ($X$ and $X^2$)\n",
    "  2. Data: Present in the data of itself, instead of coming from the model. Observational experiments tend to show this kind of multicollinearity\n",
    " \n",
    "---\n",
    "### Problems caused by Multicollinearity\n",
    "* Wildly changing coefficients: Coefficients become very sensitive to small changes in the model.\n",
    "* Lower ability to detect significant coefficients: Reduces the precision of the estimated coefficients, which weakens the statistical power of your regression model.\n",
    "\n",
    "---\n",
    "-  You might not be able to trust the p-values to identify independent variables that are statistically significant\n",
    "-  Imagine fitting a regression model and the coefficient values and even the signs change dramatically with the IVs you include in the model. It is disconcerting feeling when slightly different models lead to very different conclusions, almost like you dont know the actual effect each IV has on the model\n",
    "-  Additionally, you cant even trust the p-values to decide what IVs to include in the model\n",
    "-  This problem makes it difficult to both specify the correct model and to justify the model if your p-values are not statistically significant\n",
    "-  As the severity fo the multicollinearity increases, so do these problematic effects\n",
    "-  However, these issues only affect those IVs that are correlated, so you can ahve a modle with severe multicollinearity, and yet some of the variables in the model will be completely unaffected\n",
    "---\n",
    "\n",
    "### Should it be fixed?\n",
    "* It can make it hard to interpret your coefficients and it reduces the power of your model to identify independent variables that are statistically significant\n",
    "* The good news is you dont always have to find a way to fix multicollinearity. It depends on :\n",
    "  - severity of the multicollinearity\n",
    "  - primary goal of the regression model\n",
    "* Keep these points in mind:\n",
    "  - The severity of the problems increases with the degree of multicollinearity\n",
    "  - Since multicollinearity only affects the specific IVs that are correlated, if you're not interested in those specific variables, then no need to deal with multicollinearity\n",
    "  - Multicollinearity affects the coefficients and p-values, but it does not influence the predictions, the precision of the predictions or the goodness-of-fit stats\n",
    "---\n",
    "\n",
    "### VIF\n",
    "* The Variance Inflation Factors (VIFs) identify the strength of correlation betweent the IVs and the strength of the correlation\n",
    "* They start at 1 and have no upper limit, so $\\text{VIF}\\in[1,\\infty)$\n",
    "  - $1-5$: Moderate, no corrective measures\n",
    "  - $>5$: severe, coefficients and p-values are questionable\n",
    "  \n",
    "---\n",
    "### Fixing multicollinearity\n",
    "* If its *Structural*: center your continuous variables\n",
    "* Data:\n",
    "  - Remove some of the highly correlated IVs\n",
    "  - Linearly combine correlated IVs.\n",
    "  - Use LASSO or Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "493e9cb9-70d1-4950-8ddc-f6fc0878a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
